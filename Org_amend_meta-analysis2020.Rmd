---
title: "Ometa_Organic_Amendment_Meta_Analysis"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

Updated: 20200722 EJF
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
GOAL: 
Meta-analysis on soil organic amendment impact on soil carbon pools > 20cm in depth
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
STATS OVERVIEW:
mixed model for meta-analysis (regression?) with maximum likelihood 
       (hierarchical w study and depth as groups) 
       OR I could run different analyssis every 20cm
       
parameter = carbon stock 
moderators = initial soil conditions, other environmental factors, management
covariate = length of study (months)??
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r, A. (1) prelimary - load packages, include=FALSE}
#include=FALSE supress this output when knitting doc
uzdir<-("/Users/macuser/Dropbox/9Meta_analysis_organic/Statistical_meta_analysis/Ometa2019") #save long name as user directory uzdir
setwd(paste(uzdir))  #set your working directory/file
source(file="EJF_libraries.R") #install packages, use old vegan 
```

```{r, B. load data and subset, response ratio + error calculations, include=FALSE}
#echo=FALSE do not incldue code when knitting doc 
#include=FALSE supress this output when knitting doc

##########################################################################################################
###
### 2. LOAD DATA AND SUBSET
###
##########################################################################################################
#rm(list = ls()) # if you want to reset your environment by deleating everything
df1<-read.csv("Ometa_table.csv", header=T, na.strings= c(""," ", "na", "nd", "NA"), skip=1)
str(df1) 
ncol(df1)
nrow(df1)

#last 4 rows are empty
df1<-df1[-c(4076:4079),]
#colnames(df1)

#number of studies included
length(unique(df1$ACC))
length(unique(df1$country))
df1$X_a<-as.numeric(df1$X_a); df1$X_cf<-as.numeric(df1$X_cf); df1$X_cmin<-as.numeric(df1$X_cmin)
names(df1)

names(df1)
#select important columns
df1 %>% dplyr::select(X3,ACC, 
                      crop_group, crop_system, irrigated, tillage_type , tillage_depth,    
                      till_depth_group, Nfert_rate, Nfert_group,  Pfert_rate, NPK_rate,
                      depth.start ,  depth.end ,  param ,  param_group ,  units , 
                      exp_duration_mos,  duration_group,  duration_even , 
                       lat.dec.degree, country , elevation ,  lat_group , MAT ,  MAP ,
                      pH, clay, clay_group ,  pH_group ,  SOC_g.kg, SOC_int_group, BD,
                      amend, amend_group, weight.dry,  C.rate_Mg.ha, C.N_rate, C.rate_group, amend_N_kg.ha,amend_N_kg.ha_group,
                      X_cf, SE_cf, SD_cf, N_cf, X_a, SE_a, SD_a, N_a, X_cmin, SE_cmin, SD_cmin, N_cmin, trt_name ) -> df2 

#create depth by groups here #Courtland
df.c$depth<-(df.c$depth.end+df.c$depth.start)/2

#rename cmin to zf (zero fertilized control)
df<-dplyr::rename(df2, X_zf=X_cmin, SE_zf=SE_cmin, SD_zf=SD_cmin , N_zf=N_cmin)

df %>% dplyr::select(X_cf, SE_cf, SD_cf, N_cf, X_a, SE_a, SD_a, N_a, X_zf, SE_zf, SD_zf, N_zf)-> df.result 

#many data types are extracted, select soil carbon as the initial response parameter
 #subgroups will be used to addresss questions about stability
param<-unique(df$param)
  df1[which(df$param=="SOC"|df$param=="C"), ]$ACC %>% unique() %>% length() #SOC = 49
  

#C = 10
df[which(df$param=="SOC"), ]$ACC %>% unique() %>% length() #SOC = 46
#df[which(df$param=="POM"| df$param=="LF"), ]$ACC %>% unique() %>% length() #LF+POM = 4
#df[which(df$param=="C_POM"), ]$ACC %>% unique() %>% length() #C_POM = 1
#df[which(df$param=="C_MAOM" | df$param=="MAOM"), ]$ACC %>% unique() %>% length() #C_POM = 3
#df[which(df$param=="MAOM"), ]$ACC %>% unique() %>% length() #C_POM = 3 

##########################################################################################################
###
### 3. INITIAL PLOTS
###
##########################################################################################################
#plot(df$amend_group_brd, df$C.N_rate) 

plot(df$country); axis(2,cex.axis=1)  
plot(df$depth.end)
plot(df$param_group, main="Parameters - Reponse Variables")
plot(df$tillage_type, main = "Tillage Groups")
plot(df$crop_group, main= "Crop Types")
plot(df$crop_system)
hist(df$lat.dec.degree, main= "Latitude")
     hist(df$elevation, main= "Elevation", xlab="Elevation (m)")
     plot(df$MAP, df$MAT)
     #hist(df$year.zero, main="First Year of Study", xlab="Year")
     #hist(df$exp_duration_mos, main="Study Length", xlab="Months of Experiment")
      plot(df$duration_even, main="First Year of Study", xlab="Year")
     hist(df$MAP, main="Precipitation", xlab="MAP (mm)")
      hist(df$MAT, main="Temperature", xlab="MAT (degrees C)")
hist(df$clay, main="Percent Clay", xlab="Clay (%)")
hist(df$depth.end)
plot(df$crop_system)
plot(df$duration_group, main="Study Duration", xlab= "Years")
  #  plot(df$irrigation_group, main ="Cateogry of Irrigation")
   plot(df$till_depth_group, main ="Tillage depths")
   hist(df$pH, xlab="pH")  
   plot(df$SOC_int_group, main="Initial SOC", xlab="SOC g/kg")
   
##########################################################################################################
###
### 4. RESPONSE RATIOS, weights of ratios, % change
###
##########################################################################################################
#current dataframess = df and df.result 
#calculate SD from SE= SD/ sqrt(n)  => SE*sqrt(n)

#if the value is Na, replace with SD calculated from SE
SD.to.replace<-which(is.na(df$SD_a)); length(SD.to.replace) #of 4079 obs
df$StDev_a<-df$SD_a
df$StDev_a<-ifelse(is.na(df$StDev_a),  #if SD = NA
         df[SD.to.replace ,]$SE_a * sqrt(df[SD.to.replace, ]$N_a), #replace with SE * sqrt of n
       df$StDev_a)

#calculate the weight of each study based off of observation numbers (Hedges adn Olkin 1985)
  df$w.cf<-(df$N_a*df$N_cf)/(df$N_a+df$N_cf)
  df$w.zf<-(df$N_a*df$N_zf)/(df$N_a+df$N_zf)

which(is.na(df$N_a))
which(is.na(df$N_zf))
which(is.na(df$N_a))
which(is.na(df$N_zf))
  
#calculate response ratio for each observation:
ratio_zf<-log(df$X_a/df$X_zf)
   nan.check<-df[which(is.nan(ratio_zf)), ]; names(nan.check) #determine which values are NaN
   nan.check[c(6, 24:ncol(nan.check))] #print which values are NaN
    percent.change.zf<-(exp(ratio_zf) -1)*100 #mean % change = (e^ln(rr)-1)*100
    
ratio_cf<-log(df$X_a/df$X_cf)
    percent.change.cf<-(exp(ratio_cf)-1)*100 

#create new df2 with ratios calculated for each obs
df2<-cbind(df, ratio_zf, percent.change.zf, ratio_cf, percent.change.cf) #create df with response ratios

#remove NaNs/ Inf
is.na(df2$ratio_zf) <- is.infinite(df2$ratio_zf)
is.na(df2$ratio_zf) <- is.nan(df2$ratio_zf)
is.na(df2$ratio_cf) <- is.infinite(df2$ratio_cf)
is.na(df2$ratio_cf) <- is.nan(df2$cf_zf) 

##########################################################################################################
###
### 5. SUBSET AND CALCULATE SOIL CARBON STOCKS
###
##########################################################################################################
df.c<-subset(df2, param == "C" |param == "SOC" ) #subset by carbon parameters only, obs=537

### create column of ACC + trt name
df.c<-unite(df.c, At, c(ACC, trt_name), sep = "_", remove = FALSE, na.rm = FALSE) 
df.c$ACC<-as.factor(df.c$ACC)
str(df.c)

#subset by zero or fertilized controls
#remove rows with NA for response ratio - as these obvs cannot be analyzed
mydf.cf<-df.c[which(!is.na(df.c$ratio_cf)),]  
mydf.zf<-mydf.zf<-df.c[which(!is.na(df.c$ratio_zf)),]
  
#calculate carbon stocks from g.kg  (g.kg/1000)*BD*(depth.end-depth.start) = g/cm2
# Convert to t/ha => g/cm2 * (1Mg/ 1,000,000g)*(1*10^8cm2/ha) = 100
   #(1/1000000)*(1*10^8/1) 
df.c$X_a_stock<-ifelse(df.c$units == "g.kg", 
                       df.c$X_a/1000 * df.c$BD * (df.c$depth.end-df.c$depth.start) * 100, 
                       df.c$X_a/1000) #else divides the kg/ha by 1000 to get Mg/ha
df.c$X_zf_stock<-ifelse(df.c$units == "g.kg", 
                       df.c$X_zf/1000 * df.c$BD * (df.c$depth.end-df.c$depth.start) * 100, 
                       df.c$X_zf/1000) #else divides the kg/ha by 1000 to get Mg/ha
df.c$X_cf_stock<-ifelse(df.c$units == "g.kg", 
                       df.c$X_cf/1000 * df.c$BD * (df.c$depth.end-df.c$depth.start) * 100, 
                       df.c$X_cf/1000) #else divides the kg/ha by 1000 to get Mg/ha
  
#convert error to metric t/ha (or Mg/ha)
df.c$SD_a_stock<-ifelse(df.c$units == "g.kg", 
                       df.c$SD_a/1000 * df.c$BD * (df.c$depth.end-df.c$depth.start) * 100, 
                       df.c$SD_a/1000) #else divides the kg/ha by 1000 to get Mg/ha
df.c$SD_zf_stock<-ifelse(df.c$units == "g.kg", 
                       df.c$SD_zf/1000 * df.c$BD * (df.c$depth.end-df.c$depth.start) * 100, 
                       df.c$SD_zf/1000) #else divides the kg/ha by 1000 to get Mg/ha
df.c$SD_cf_stock<-ifelse(df.c$units == "g.kg", 
                       df.c$SD_cf/1000 * df.c$BD * (df.c$depth.end-df.c$depth.start) * 100, 
                       df.c$SD_cf/1000) #else divides the kg/ha by 1000 to get Mg/ha

mean(df.c$ratio_cf, na.rm=TRUE); 
mean(df.c$ratio_zf, na.rm=TRUE) #higher ratio with zero-fertilizer on controls

##########################################################################################################
###
### 6. IMPUTE ERROR
###
##########################################################################################################
#impute error over all depths/amendents for df.c

str(df.c) #525 obs
#estimate ratio to impute error for amend trt / cf control / zf control
est.SD.a<-sum(df.c$SD_a, na.rm=T)/sum(df.c$X_a,na.rm=T)
est.SD.cf<-sum(df.c$SD_cf, na.rm=T)/sum(df.c$X_cf, na.rm=T)
est.SD.zf<-sum(df.c$SD_zf, na.rm=T)/sum(df.c$X_zf, na.rm=T)

#ratio of SD/X (est.XXX) * mean to impute error (FYI, must use is.na not df.c$X=="NA" (won't return a TRUE, just na and ifelse doesn't work))
df.c$SD_a_imp<-ifelse(is.na(df.c$SD_a), yes=df.c$X_a*est.SD.a, no=df.c$SD_a)
df.c$SD_cf_imp<-ifelse(is.na(df.c$SD_cf), df.c$X_cf*est.SD.cf, df.c$SD_cf)
df.c$SD_zf_imp<-ifelse(is.na(df.c$SD_zf), df.c$X_zf*est.SD.zf, df.c$SD_zf)

#amendment errors reported
error.amend<-(1-length(which(is.na(df.c$StDev_a)))/nrow(df.c))*100; error.amend #36% have error reported

#impute error via regression S = alpha +beta(n)
  lm(df.c$SD_cf ~ df.c$N_cf, na.action=na.omit) #cf intercept/alpha= 26.430 m/beta= -6.166
 lm(df.c$SD_zf ~ df.c$N_zf, na.action=na.omit) #zf intercept/alpha= 12.210 m/beta= -2.461 
  lm(df.c$SD_a ~ df.c$N_a, na.action=na.omit) #a intercept/alpha= 25.731 and m/beta=-5.496

#regression to impute error save as new column
df.c$SD_cf_reg<-ifelse(is.na(df.c$SD_cf), 26.430-6.166*(df.c$N_cf), df.c$SD_cf)
df.c$SD_zf_reg<-ifelse(is.na(df.c$SD_zf), 12.210-2.461*(df.c$N_zf), df.c$SD_zf)
df.c$SD_a_reg<-ifelse(is.na(df.c$SD_a), 25.731-5.496*(df.c$N_a), df.c$SD_a)

### create column of response ratios with fertlized controls as main effets, and only use zero controls when other option not possible
#dataframes with non NAs for fert and zero controls = mydf.fert; mydf.zf and combined
str(df.c)
mydf.cf$ratio_comb<-mydf.cf$ratio_cf
mydf.zf$ratio_comb<-mydf.zf$ratio_zf
mydf.cf$SD_all<-mydf.cf$SD_cf_imp
mydf.zf$SD_all<-mydf.zf$SD_zf_imp
mydf.cf$w_all<-mydf.cf$w.cf
mydf.zf$w_all<-mydf.zf$w.zf 

names(df.c)
#to combine datasets - use fertilized controls when possible= had a lower effect size (will not overestimate the effect?)
#left outer join
 df.c$ratio_all<-ifelse(is.na(df.c$ratio_cf),  df.c$ratio_zf, df.c$ratio_cf)
  df.c$SD_all<-ifelse(is.na(df.c$ratio_cf), df.c$SD_zf_imp, df.c$SD_cf_imp) #imputed std deviations
  df.c$w_all<-ifelse(is.na(df.c$ratio_cf), df.c$w.zf, df.c$w.cf)
df.c$control.type<-ifelse(is.na(df.c$ratio_cf), "zf", "cf")

#check normality of ratio distribution 
f<-df.c$ratio_cf
z<-df.c$ratio_zf
all<-(df.c$ratio_all)

hist(f); hist(z); hist(all)
qqnorm(f);qqline(f) #1 outlier 
qqnorm(z);qqline(z)
qqnorm(all); qqline(all)
df.c$ratio_all[df.c$ratio_all >1.9] <-"NA"

df.c$ratio_all<-as.numeric(df.c$ratio_all) #make ratio_all numeric, after adding the NA

shapiro.test(f) #not normal
shapiro.test(z) #not normal
shapiro.test(df.c$ratio_all)

#make response variable numeric
str(df.c)
df.c$ratio_all<-as.numeric(df.c$ratio_all)

#where are the outliers? for ratio.zf and ratio.cf
#mean.ratio<- df2 %>%
#  group_by(ACC) %>%
#  summarise(mean.f = mean(ratio_cf),
#            mean.zf = mean(ratio_zf), n= n()); mean.ratio

#mean.ratio<- df2 %>%
#  group_by(ACC) %>%
#summarise_all(funs(mean, n), na.rm = TRUE); mean.ratio

##########################################################################################################
###
### 7. BOOTSTRAP for 95% CI and mean, over all depths
###
##########################################################################################################
# use bias corrected CIs (account for non parametric data)
#create one depth variable, mean of depth start and stop
df.c$depth<-(df.c$depth.end+df.c$depth.start)/2 #Courtland - could create depth group here
#df.sub<-subset(df.c, depth <= 20); length(df.sub) #subset by depth

#create function to resample with
boot_mean <- function(df_vector, resample_indices) {
    mean(df_vector[resample_indices])
}
#boot_var <- function(df_vector, resample_indices) {
#    (sd(df_vector[resample_indices])^2 )
#}
set.seed(12345)
#moderators of interest: exp_duration_mos, amend_group, clay, lat.dec.degree

#########################################
# 7a. data frame with fertilized controls 
#########################################
mean(mydf.cf$ratio_cf) #mean response ratio
#mean(mydf.cf$ratio_cf)-1 #percent change RR=1 no effect (Kallenbach)
mean(mydf.cf$percent.change.cf) #percent change (Pressler 2018)

results.cf <- boot(data=mydf.cf$ratio_cf, statistic=boot_mean, R=1000, weights=mydf.cf$w.cf) # dist looks more evenly distriuted around mean without the weights
                #formula=ratio_cf~depth) #strata=ACC?depth?
plot(results.cf)
summary(results.cf) #mean RR = 0.14866
boot.ci(results.cf) #,type="bca") #significant if do not inclue 1
 #Pnormale 95%    ( 0.1569,  0.2054 )

#percetn lower or higher than observed mean
Higher<- length (which( results.cf$t >mean(summary(results.cf)$original)) )/length(results.cf$t)
Lower <-length (which(results.cf$t < mean(summary(results.cf)$original)) )/length(results.cf$t)
meanLrgerData<-summary(results.cf)$original > results.cf$data
  ifelse( length(which(meanLrgerData))> .5*length(meanLrgerData), "Need to bias correct", "Great work!")
str(results.cf)
#########################################
# 7b. data frame control zero/minimum inputs
#########################################

#moderators of interest: exp_duration_mos, amend_group, clay, lat.dec.degree
 
mean(mydf.zf$ratio_zf) # mean RR
#mean(mydf.zf$ratio_zf)-1 #percent change (Kallenbach 2011)
mean(mydf.zf$percent.change.zf) #percent change (Pressler 2018)

results.zf <- boot(data=mydf.zf$ratio_zf, statistic=boot_mean, R=1000, weights=mydf.zf$w.zf)
                #formula=ratio_cf~depth) #strata=ACC?depth?
plot(results.zf)

boot.ci(results.zf) #, type="bca") #bias corrected?
summary(results.zf)
meanLrgerData<-summary(results.zf)$original > results.zf$data
  ifelse( length(which(meanLrgerData))> .5*length(meanLrgerData), "Need to bias correct", "Great work!")
  
str(results.zf)
#formula=ratio_cf~depth) #strata=ACC?depth?


### PLOTS
# CF 0.14866 ( 0.1569,  0.2054 )
# ZF 0.067939 ( 0.0657,  0.0868 )

y1=.25; y2=.75
plot(.068184, y1 ,ylab="Study type", xlab="Effect Size", xlim=c(-.5,.5), ylim=c(0,1), 
     pch=16, cex=1); abline(v=0)
arrows(y0=y1, x0=0.0652, y1=y1, x1=0.0868, code=3, angle=90, length=.05, col="black") #error bars
points(.14995, y2)
arrows(y0=y2, x0=0.1569, y1=y2, x1=0.2054, code=3, angle=90, length=.05, col="blue") #error bars
 
##########################################################################################################
###
### 8. Q = check heterogeneity of studies in meta-analysis
###
##########################################################################################################
#see pg 109-113 Koricheva 2013 handbook of meta-anaysis for ecology
#check QT using K against chi-sq distrubtion: https://www.socscistatistics.com/pvalues/chidistribution.aspx
  #note random effects models should take this QT between study heterogeniety into account, 

### so QT is not a useful statistic for the global meta-analysis with random effects###

#check signficant against the X2 distribution:
# http://hamelg.blogspot.com/2015/08/introduction-to-r-part-25-chi-squared.html

#mu.hat = sum(w.k*theta.k)/sum(w.k)
#QT = sum (w.k* (theta.k-mu.hat)^2)
#I2 = max ((100*( (QT-(K-1))/QT)),0)
#########################################
#8a. fertilized controls
#########################################
w.cf<-mydf.cf$w.cf 
theta.cf<-mydf.cf$ratio_cf
mu.cf <- sum(w.cf*theta.cf)/sum(w.cf) #0.1495921; % change 16.13
QT.cf <- sum (w.cf* (theta.cf-mu.cf)^2) #not meaningful for random effects models, compare to X2 distrubtion, 50.09 (X2 p-value = .18 , not sig )

K.cf <- length(unique(mydf.cf$ACC)) #42
I2.cf = max ((100*( (QT.cf-(K.cf-1))/QT.cf)),0)
#18% of observed variance can be attribted to difference among the studies
     #rerea 3.18.20 and found 5% explained

 #chisq.test(x = observed(theta.cf), p = expected)
1-pchisq(q=QT.cf, df=(K.cf-1)) #ACC not significant
1-pchisq(q=I2.cf, df=(K.cf-1))

#########################################
#8b. zero input controls
#########################################
w.zf<-mydf.zf$w.zf 
theta.zf<-mydf.zf$ratio_zf; hist(theta.zf); shapiro.test(theta.zf)
mu.zf <- sum(w.zf*theta.zf)/sum(w.zf) #0.2792475; %change 32.21
QT.zf <- sum (w.zf* (theta.zf-mu.zf)^2) #looked up X2 p-value = 0.2236, not sig
K.zf <- length(unique(mydf.zf$ACC)) #39
I2.zf = max ((100*( (QT.zf-(K.zf-1))/QT.zf)),0)
#16% of observed variance can be attribted to difference among the studies

#get p-value, testing backtransformed ratios against X2 distribution with K-1 for df
 1-pchisq(q=QT.zf, df=(K.zf-1)) #ACC is not significant
 1-pchisq(q=I2.zf, df=(K.zf-1)) #ACC not significant - not sure if this test makes statistical sense, just curious
 
#########################################
#8c. combined (all) controls
#########################################
w.comb<-c(mean(w.cf), mean(w.zf))
theta.comb<-c(mean(theta.cf), mean(theta.zf))
mu.comb<-c(mean(mu.cf), mean(mu.zf))
QT.comb<-sum(QT.cf, QT.zf)
K.comb <- sum(K.zf, K.cf) #81
I2.comb = max ((100*( (QT.comb-(K.comb-1))/QT.comb)),0) #16.2% of variance explained by ACC
 #chisq.test
 1-pchisq(q=QT.comb, df=(K.comb-1)) #not significant
1-pchisq(q=I2.comb, df=(K.comb-1)) #not significant
```

```{r, C. Graphs + Check regression assumptions and for correlation among parameters}
####################################################################################################
###
### 10. Check 4 assumptions of regression  https://peerj.com/articles/3323/
### (linearity, normality of error, homoscedasticity - plot resid, independence of error)
###      (10 assumptions listed here:
####################################################################################################
names(df.c)

#continuous: C.rate_Mg.ha, C.N_rate, N.amend_g.kg,ç, Nfert_rate
   #env continuous: MAT, MAP, MAP/MAT, lat.dec.degree
    #initial continuous: SOC_g.kg, pH, clay

#factor: At, crop_group, crop_system, irrigated, tillage_type, till_depth_group, Nfert_group, duration_group, duration_even, country,
# lat_group, clay_group, pH_group, SOC_int_group, amend, amend_group, C.rate_group, amend_N_kg.ha_group

#subgroup analysis???
levels(df.c$crop_group)
levels(df.c$crop_system)
levels(df.c$tillage_type)
# exp_duration_mos

#set up linear model  #yield? #total amount of C added over the experiment
rma1 <- rma.mv(ratio_all, V=SD_all, 
             mods = ~ MAT+ MAP+ pH+ clay+ SOC_g.kg + #latitude.dec.degree + exp_duration_mos + C.N_rate
                  C.rate_Mg.ha+ amend_N_kg.ha + Nfert_rate, random= ~1|ACC,
            data=df.c, W=w_all, method="ML"); rma1 #important to use ML (instead of REML) estimation, since log-likelihoods (& hence information criteria) are not directly comparable for models with different fixed effects

#Erika which factors have NAs
is.na(df.c$MAT); is.na(df.c$MAP); lat.dec.degree


#install.packages("broom")
library(broom) #testing plots to check assumptions - didn't run with rma output
 #model.diag.metrics <- augment(rma1); head(model.diag.metrics)
 
#graph residuals
#ggplot(model.diag.metrics, aes(youtube, sales)) +
#  geom_point() +
#  stat_smooth(method = lm, se = FALSE) +
#  geom_segment(aes(xend = youtube, yend = .fitted), color = "red", size = 0.3)

#########################################
# 10a. correlation of covariates minimized (multicolinearity)
#########################################
param.corr<-select(df, MAT, MAP, lat.dec.degree, elevation, pH, clay, SOC_g.kg,
                  C.rate_Mg.ha, C.N_rate, amend_N_kg.ha, exp_duration_mos, Nfert_rate)
param.corr$MAT.MAP<-df$MAT/df$MAP
names(df.c)
pear<-rcorr(as.matrix(param.corr), type = "pearson") ; pear
#CORRELATED: pH and MAT = .98 and MAT/MAP =.65; 
           #elevation and exp_duration_mos (.97); elevation and MAT.MAP .76,  lat and Nfert.rate .333 + amend_N =.32;
# !!! remove elevation and MAT !!!

#########################################
# 10b. test normality of errors
#########################################
res1<-residuals(rma1); hist(res1) #residuals normally distributed around 0
qqnorm(res1); qqline(res1); shapiro.test(res1) #check normality of residuals
mean(res1, na.rm=T) #check mean of resid = ~0

#########################################
# 10c. test homoscedasticity of variance
#########################################
plot(res1); abline(0,0)

#also see plots in section 11

#########################################
# 10d. test independence of residuals (autocorrelations)
#########################################
acf(res1) #on plot if there is acorrelation = 1, no correlation = 0
 #cor.test(df$MAP, res1) #reject null, alternative = true correlation not equal 0

```



```{r, 11.  Graphs of response ratios}
### USING ACC ###
#########################################
### 11a GRAPHS OF RESPONSE RATIOS ie, plot within study variance w/ ACC
#########################################
y<-df.c$ratio_all
x<-as.numeric(unique(df.c$ACC))
trt<-levels(df.c$trt_name)

M = tapply(y,
           INDEX = df.c$ACC,
           FUN   = mean, na.rm=T)

SD = tapply(y,
           INDEX = df.c$ACC,
           FUN   = sd, na.rm=T); length(SD); length(x); length(M)

MA<-mean(df.c$ratio_all, na.rm=T)
SDA<-sd(df.c$ratio_all, na.rm=T) 
plot.new()
### ALL plot means and sd of each study
plot(M, x,ylab="ACC", xlab="Effect Size", xlim=c(-1,1), ylim=c(-5,50), 
     pch=16, cex=.001)
 abline(v=0); abline(v=MA, lty=2, col="blue", lwd=2)

y_grand.mean<-(-3)
 arrows(y0=x, x0=M-SD, y1=x, x1=M+SD, code=3, angle=90, length=0.025, col="darkgray") #error bars
 arrows(y0=y_grand.mean, x0=MA-SDA, y1=y_grand.mean, x1=MA+SDA, code=3, angle=90, length=0.025, lty=2, col="blue") #1150 is the 'pretend' ACC to plot the grand mean

points(M, x,pch=16,cex=.75)
points(MA, y_grand.mean, col="blue", pch=5,cex=2)

(exp(MA)-1)*100 # % change with amendment

#########################################
### 11b plot zero controls only w/ ACC (!!! CURRENTLY NOT WORKING !!!)
#########################################
y<-mydf.zf$ratio_zf
x<-levels(mydf.zf$ACC)
   
M = tapply(y,
           INDEX = mydf.zf$ACC,
           FUN   = mean, na.rm=T)

SD = tapply(y,
           INDEX = mydf.zf$ACC,
           FUN   = sd, na.rm=T); length(SD); length(x); length(M)

MA<-mean(mydf.zf$ratio_zf, na.rm=T)
SDA<-sd(mydf.zf$ratio_zf, na.rm=T) 

### ZERO plot means and sd of each study
plot(M, x,ylab="ACC", xlab="Effect Size",
       pch=16, cex=.001, xlim=c(-1,1), ylim=(c(200,1200)) )
 abline(v=0); abline(v=MA, lty=2, col="blue", lwd=2)

 y.mean<-1150
 arrows(y0=x, x0=M-SD, y1=x, x1=M+SD, code=3, angle=90, length=0.025, col="darkgray") #error bars
 arrows(y0=y.mean, x0=MA-SDA, y1=y.mean, x1=MA+SDA, code=3, angle=90, length=0.025, lty=2, col="blue") #1150 is the 'pretend' ACC to plot the grand mean

points(M, x,pch=16,cex=.75)
points(MA, y.mean, col="blue", pch=5,cex=2)

(exp(MA)-1)*100 # % change with amendment 32% for zero fertilized controls

#########################################
### 11c plot controls w fertilizer w/ ACC !!! CURRENTLY NOT WORKING - DIFFERENT LENGTH OF X !!!
#########################################
y<-mydf.cf$ratio_cf
x<-unique(mydf.cf$ACC)
   
M = tapply(y,
           INDEX = mydf.cf$ACC,
           FUN   = mean, na.rm=T)

SD = tapply(y,
           INDEX = mydf.cf$ACC,
           FUN   = sd, na.rm=T); length(SD); length(x); length(M) #x is 42, not 49

MA<-mean(mydf.cf$ratio_cf, na.rm=T)
SDA<-sd(mydf.cf$ratio_cf, na.rm=T) 

plot.new()
### FERTILIZED CONTROL plot means and sd of each study
plot(M, x,ylab="ACC", xlab="Effect Size",
       pch=16, cex=.001, xlim=c(-1,1), ylim=(c(200,1200)) )
 abline(v=0); abline(v=MA, lty=2, col="red", lwd=2)

 arrows(y0=x, x0=M-SD, y1=x, x1=M+SD, code=3, angle=90, length=0.025, col="darkgray") #error bars
 arrows(y0=1150, x0=MA-SDA, y1=1150, x1=MA+SDA, code=3, angle=90, length=0.025, lty=2, col="red") #1150 is the 'pretend' ACC to plot the grand mean

points(M, x,pch=16,cex=.75)
points(MA, 1150, col="red", pch=5,cex=2)

(exp(MA)-1)*100 # % change with amendment 17% for fertilized controls (32% for zero-fertilized controls)

### USING ACC + Treatment name ###
#########################################
### 11d GRAPHS OF RESPONSE RATIOS ie, plot within study variance ACC+trt
#########################################
y<-df.c$ratio_all
x<-seq(1,length(unique(df.c$At)),1) #create a sequence of numbers to represent the ACC+trt
str(df.c$At)
trt<-levels(df.c$trt_name)

M = as.numeric(tapply(y,
           INDEX = df.c$At,
           FUN   = mean, na.rm=T))

SD = as.numeric(tapply(y,
           INDEX = df.c$At,
           FUN   = sd, na.rm=T))

length(SD); length(x); length(M)

str(SD)
MA<-mean(df.c$ratio_all, na.rm=T)
SDA<-sd(df.c$ratio_all, na.rm=T) 
plot.new()
### ALL plot means and sd of each study ACC+trt
plot(M, x, ylab="ACC & Treatments", xlab="Effect Size (all)",
      xlim=c(-1,1), ylim=(c(0,130)),
       pch=16, cex=.001)
 abline(v=0); abline(v=MA, lty=2, col="blue", lwd=2)
yforAT<-130 #125 is the 'pretend' At to plot the grand mean
   arrows(y0=x, x0=M-SD, y1=x, x1=M+SD, code=3, angle=90, length=0.025, col="darkgray") #error bars
   arrows(y0=yforAT, x0=MA-SDA, y1=yforAT, x1=MA+SDA, code=3, angle=90, length=0.025, lty=2, col="blue") 
points(M, x,pch=16,cex=.75)
points(MA, yforAT, col="blue", pch=5,cex=2)

(exp(MA)-1)*100 # % change with amendment

#########################################
### 11e plot zero controls only  ACC+trt !!! NOT WORKING,  X and Y lengths differ, need to edit !!!
#########################################
y<-subset(df.c, control.type="zf")$ratio_zf
x<-seq(1,length(unique(mydf.cf$At)),1)

M = as.numeric(tapply(y,
           INDEX = mydf.zf$At,
           FUN   = mean, na.rm=T))

SD = as.numeric(tapply(y,
           INDEX = mydf.zf$At,
           FUN   = sd, na.rm=T)); length(SD); length(x); length(M)

MA<-mean(mydf.zf$ratio_zf, na.rm=T)
SDA<-sd(mydf.zf$ratio_zf, na.rm=T) 

### ZERO plot means and sd of each study  
plot(M, x, ylab="ACC & Treatments", xlab="Effect Size",
      xlim=c(-2,2), ylim=(c(0,130)),
       pch=16, cex=.001)
 abline(v=0); abline(v=MA, lty=2, col="blue", lwd=2)

 yforAT<-125
 arrows(y0=x, x0=M-SD, y1=x, x1=M+SD, code=3, angle=90, length=0.025, col="darkgray") #error bars
 arrows(y0=yforAT, x0=MA-SDA, y1=yforAT, x1=MA+SDA, code=3, angle=90, length=0.025, lty=2, col="blue") #1150 is the 'pretend' At to plot the grand mean

points(M, x,pch=16,cex=.75)
points(MA, 125, col="blue", pch=5,cex=2)
(exp(MA)-1)*100 # % change with amendment 32% for zero fertilized controls

#########################################
### 11f plot controls w fertilizer ACC+trt !!! NEEDS A FEW EDITS FOR 'POLISHED' GRAPH !!!
#########################################
y<-mydf.cf$ratio_cf
x<-seq(1,length(unique(mydf.cf$At)),1)
   
M = as.numeric(tapply(y,
           INDEX = mydf.cf$At,
           FUN   = mean, na.rm=T))

SD = as.numeric(tapply(y,
           INDEX = mydf.cf$At,
           FUN   = sd, na.rm=T)); length(SD); length(x); length(M)

MA<-mean(mydf.cf$ratio_cf, na.rm=T)
SDA<-sd(mydf.cf$ratio_cf, na.rm=T) 

### FERTILIZED CONTROL plot means and sd of each study
plot.new()
plot(M, x,ylab="ACC & Treatments", xlab="Effect Size",
       pch=16, cex=.001, xlim=c(-1.5,1.5), ylim=(c(0,100)) )
 abline(v=0); abline(v=MA, lty=2, col="red", lwd=2)

 
 arrows(y0=x, x0=M-SD, y1=x, x1=M+SD, code=3, angle=90, length=0.025, col="darkgray") #error bars
 arrows(y0=95, x0=MA-SDA, y1=95, x1=MA+SDA, code=3, angle=90, length=0.025, lty=2, col="blue") #95 is the 'pretend' At to plot the grand mean
 points(M, x,pch=16,cex=.75)
points(MA, 95, col="blue", pch=5,cex=2)
```

```{r E. IN PROGRESS CODE: Bootstrap Q values}
##########################################################################################################
### IN PROGRESS STARTING WITH THIS SECTION......
### 12. calc Qb for all paramters
###
#########################################################################################################
# bootstrap example with forumula
#https://stats.stackexchange.com/questions/298506/bias-corrected-percentile-confidence-intervals

#loop through variables
#Management
#crop_group + irrigation +crop_system + duration_even + C.rate_group + amend_N_kg.ha_group + amend_group + 
    #amend C:N 

#Environment: Soil properties 
#lat_group +clay_group + pH_group + SOC_int_group + MAP +sand_group(?)
      # + irrigation +crop_system + duration_even + C.rate_group + amend_N_kg.ha_group + amend_group + 
     #lat_group +clay_group + pH_group + SOC_int_group + MAP +sand_group

mods1<- c(names(df.c)[c(1:42)], "trt_name", "control.type", "depth")


#combined fertlized and non fertilized controls
w.comb<-c()
theat.comb<-c()
mu.comb<-c()
QT.comb<-c()
K.comb<-c()

QB
I2.comb<-c()
p.QT<-c()
p.I2<-c()


#B. zero input controls
w.zf<-mydf.zf$w.zf 
theta.zf<-mydf.zf$ratio_zf; hist(theta.zf); shapiro.test(theta.zf)
mu.zf <- sum(w.zf*theta.zf)/sum(w.zf) #0.2792475; %change 32.21
QT.zf <- sum (w.zf* (theta.zf-mu.zf)^2) #looked up X2 p-value = 0.2236, not sig
K.zf <- length(unique(mydf.zf$ACC)) #39
I2.zf = max ((100*( (QT.zf-(K.zf-1))/QT.zf)),0)
#16% of observed variance can be attribted to difference among the studies

#get p-value, testing backtransformed ratios against X2 distribution with K-1 for df
 1-pchisq(q=QT.zf, df=(K.zf-1)) #ACC is not significant
 1-pchisq(q=I2.zf, df=(K.zf-1)) #ACC not significant - not sure if this test makes statistical sense, just curious
 #16.2% of variance explained by ACC
 

#  p.value = c()
  
#  for(i in 1:ncol(mods1)){
  
#  }
#    ad = adonis(x[factors %in% c(co[1,elem],co[2,elem]),] ~ factors[factors %in% c(co[1,elem],co[2,elem])] , method =sim.method);
#    pairs = c(pairs,paste(co[1,elem],'vs',co[2,elem]));
#    F.Model =c(F.Model,ad$aov.tab[1,4]);
#    R2 = c(R2,ad$aov.tab[1,5]);
#    p.value = c(p.value,ad$aov.tab[1,6])
#  }
#  p.adjusted = p.adjust(p.value,method=p.adjust.m)
#  pairw.res = data.frame(pairs,F.Model,R2,p.value,p.adjusted)
#  return(pairw.res)
#}
##
         
#can also play with boot.mle() for a fitted model
library(FAmle)
#mle() needs to be a 
#boot.mle(all.rma.ar.null)

#check signficant against the X2 distribution:
# http://hamelg.blogspot.com/2015/08/introduction-to-r-part-25-chi-squared.html

#measurements need to be independent = can't test depths?????? 

#mu.hat = sum(w.k*theta.k)/sum(w.k) ; 
#QT = sum (w.k* (theta.k-mu.hat)^2)
#df = # classes * # comparisons -1

#mux.x = boot(data=df.c$ratio_cf, statistic=boot_mean, R=1000, weights=df.c$w_all); plot(results.cf); summary(results.cf) #mean RR = .14995; boot.ci(results.cf)
  
    #ratio <- function(d, w) sum(d$x * w)/sum(d$u * w)
       #boot(city, ratio, R = 999, stype = "w")
  
#Qw= Sum [ (effect - group bootstrapped mean)^2) / SD^2 ]
   #Qw = Sum (theta.x - mu.x)^2) / SD^2 ]
#df = # comparisons -1

#QB= Sum [ group bootstrapped mean - grand bootstrapped mean)^2) / SD^2 ]
#df = # classes -1

#A. fertilized controls
w.cf<-mydf.cf$w.cf 
theta.cf<-mydf.cf$ratio_cf
mu.cf <- sum(w.cf*theta.cf)/sum(w.cf) #0.1495921; % change 16.13
QT.cf <- sum (w.cf* (theta.cf-mu.cf)^2) #not meaningful for random effects models, compare to X2 distrubtion, 50.09 (X2 p-value = .18 , not sig )


 1-pchisq(q=QT.cf, df=(K.cf-1)) #ACC not significant
#create function to resample with
boot_mean <- function(df_vector, resample_indices) {
    mean(df_vector[resample_indices])
}
boot_var <- function(df_vector, resample_indices) {
    (sd(df_vector[resample_indices])^2 )
}
set.seed(12345)
#moderators of interest: exp_duration_mos, amend_group, clay, lat.dec.degree

#############
# example Bootstrap Run data frame with fertilized controls 
##############
#remove rows with NA for response ratio - as these obvs cannot be analyzed
mydf.cf<-df.c[which(!is.na(df.c$ratio_cf)),]  
mean(mydf.cf$ratio_cf) #mean response ratio
#mean(mydf.cf$ratio_cf)-1 #percent change RR=1 no effect (Kallenbach)
mean(mydf.cf$percent.change.cf) #percent change (Pressler 2018)

results.cf <- boot(data=mydf.cf$ratio_cf, statistic=boot_mean, R=1000, weights=mydf.cf$w.cf) # dist looks more evenly distriuted around mean without the weights
                #formula=ratio_cf~depth) #strata=ACC?depth?
plot(results.cf)
summary(results.cf) #mean RR = .14995
boot.ci(results.cf) #,type="bca") #significant if do not inclue 1
 #Percentile 95%   ( 0.1270,  0.1736 )
```





####References
Bootstrap/max likelihood: https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2001GC000253

Auto correlation rma: https://www.rdocumentation.org/packages/metafor/versions/1.9-9/topics/rma.mv
lmer models with random effects (and intercepts): https://stats.stackexchange.com/questions/31569/questions-about-how-random-effects-are-specified-in-lmer

AIC and BIC explainations:
https://stats.stackexchange.com/questions/81427/aic-guidelines-in-model-selection

```{r, 0. climate data, eval=FALSE}
#http://www.worldclim.org/formats1

#tmean , prec ; 12 data layers 1 for each month
#BIO1 = Annual Mean Temperature; BIO2 = Mean Diurnal Range (Mean of monthly (max temp – min temp)); BIO3 = Isothermality (BIO2/BIO7) (* 100)
#BIO4 = Temperature Seasonality (standard deviation *100); BIO5 = Max Temperature of Warmest Month, BIO6 = Min Temperature of Coldest Month
#BIO7 = Temperature Annual Range (BIO5-BIO6), BIO8 = Mean Temperature of Wettest Quarter, BIO9 = Mean Temperature of Driest Quarter
#BIO10 = Mean Temperature of Warmest Quarter, BIO11 = Mean Temperature of Coldest Quarter, BIO12 = Annual Precipitation
#BIO13 = Precipitation of Wettest Month, BIO14 = Precipitation of Driest Month, BIO15 = Precipitation Seasonality (Coefficient of Variation)
#BIO16 = Precipitation of Wettest Quarter, BIO17 = Precipitation of Driest Quarter, BIO18 = Precipitation of Warmest Quarter, BIO19 = Precipitation of Coldest Quarter

#download resolution of climate data desired: http://worldclim.org/version2 #version 2 = 1970-2000
  #or version 1.4, under generic grid format, downlaod bioclim 2.5 from https://www.worldclim.org/current

#r <- raster::getData("worldclim",var="bio",res=2.5)


# also possible to get future climate data: 
# https://rdrr.io/cran/raster/man/getData.html

#r <- r[[c(1,12)]] #Bio1 and Bio12 selected
#names(r) <- c("Temp","Prec")

#lats <- c(df$lat.dec.degree) #use spTransform if not in WGS 84 lat/lon (EPSG 4326)
#longs <- c(df$long.dec.degree) 
# coords <- data.frame(x=longs,y=lats)

# points <- SpatialPoints(coords, proj4string = r@crs)
# values <- raster::extract(r,points)

#df.clim <- cbind.data.frame(coordinates(points),values); head(df.clim,2)
#df.clim$Temp<-df.clim$Temp/10 #WorldCLim data hs a scale factor of 10 for temp
#WriteXLS(df.clim, "ometa_climate.xls") #specific file here

```

